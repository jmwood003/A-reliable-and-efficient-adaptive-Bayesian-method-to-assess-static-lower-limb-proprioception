{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e84b8768-40c9-468d-b46c-dc9efec15ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import python libs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import expon\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import uniform\n",
    "from numpy.random import random\n",
    "plt.rcParams['text.usetex'] = False\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf90366e-9107-4d82-8e00-3ed302357eae",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2da4d2e6-5945-4257-a3c0-e076e8a28b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UniqueVals(stims, responses):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes stimulus values and responses and calculates N (total number of trials) and K (number of responses of interest) \n",
    "    for each unique stimulus values\n",
    "    \n",
    "    Inputs:\n",
    "    stims = vector of all stimuli\n",
    "    responses = vector of all responses\n",
    "    \n",
    "    Outputs:\n",
    "    unique_stims = vector of the unrepeated stimulus locations\n",
    "    Nstims = the number of times each unique stim was visited (vector)\n",
    "    Kleft = the number of times the response was left at each stim location\n",
    "    \"\"\"\n",
    "    \n",
    "    unique_stims, stim_idx = np.unique(stims, return_index=True)\n",
    "    Nstims, Kleft = [], []\n",
    "    for u in unique_stims:\n",
    "        stim_idx = np.argwhere(u==stims)\n",
    "        Nstims = np.append(Nstims,len(stim_idx))\n",
    "        Kleft = np.append(Kleft, np.sum(responses[stim_idx]))\n",
    "        \n",
    "    return unique_stims, Nstims, Kleft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "96392b02-86da-4f09-8387-5ffdc3372c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nloglik(params,X,N,K):\n",
    "    '''\n",
    "    This function returns the negative log likelihood of the parameters mu and sigma \n",
    "    for a data set \n",
    "    X = stimuli (vector)\n",
    "    N = number of trials at each X \n",
    "    K = Number of trials with the response of interest\n",
    "    '''   \n",
    "    alpha=params[0]\n",
    "    beta=params[1]\n",
    "    \n",
    "    psi = norm.cdf(X,alpha,beta)       \n",
    "    ll = np.sum(K * np.log(psi) + ((N - K) * np.log(1-psi)))\n",
    "\n",
    "    nll = -ll\n",
    "    \n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67dc1a31-d6b2-490f-a26c-79f014706b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fit_psi(stims, responses, Num_Inits):\n",
    "    \"\"\"\n",
    "    Definition: Uses MLE to fit a psychometric function (normcdf) to data\n",
    "    \n",
    "    inputs:\n",
    "    stims = vector of all stimulus values \n",
    "    responses = vector of all responses\n",
    "    Num_Inits = number of initializations\n",
    "    \n",
    "    outputs:\n",
    "    best_params = best paramers (size 2 vector)\n",
    "    best_ll = log likelihood of the best parameters\n",
    "    \"\"\"   \n",
    "    \n",
    "    #Calculate unique values of the stims\n",
    "    unique_stims, Nstims, Kleft = UniqueVals(stims, responses)\n",
    "\n",
    "    temp_ll = []\n",
    "    temp_params = np.empty((Num_Inits,2))\n",
    "    for i in range(Num_Inits):\n",
    "        # x0 = [np.random.randint(-30, 30), np.random.randint(0, 30)]\n",
    "        x0 = [norm.rvs(0,20), expon.rvs(0,20)]\n",
    "        \n",
    "        res = opt.minimize(nloglik, x0=x0, args=(unique_stims,Nstims,Kleft),\n",
    "                method='Nelder-Mead', bounds=((-50,50),(0,50)), options={'disp': False})\n",
    "        \n",
    "        temp_ll = np.append(temp_ll, res.fun)\n",
    "        temp_params[i,:] = res.x\n",
    "\n",
    "    min_idx = np.nanargmin(temp_ll)\n",
    "    best_params = temp_params[min_idx]\n",
    "    best_ll = temp_ll[min_idx]\n",
    "    \n",
    "    return best_params, best_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "691fef13-e68f-4be5-8530-5a9008207974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look up table\n",
    "def Psi_lookT(X,a_range,b_range):\n",
    "    \"\"\"\n",
    "    This function creates two lookup tables required for the psi algorithm to run more efficiently\n",
    "    It is a table of probabilities for both responses (left and right in this case) given all possible\n",
    "    alpha and beta values and all possible stimulus locations:\n",
    "    p(r='left'|alpha,beta,X)\n",
    "    p(r='right'|alpha,beta,X)\n",
    "    \"\"\"\n",
    "    \n",
    "    # #Set these nuisance parameters to nonzero values\n",
    "    # gam = 0.02\n",
    "    # lam = 0.02\n",
    "    \n",
    "    #Preallocate the lookup tables\n",
    "    p_left_look = np.empty([len(b_range),len(a_range),(len(X))])\n",
    "    p_right_look = np.empty([len(b_range),len(a_range),(len(X))])\n",
    "    \n",
    "    #Loop through all possible stimulus, alpha and beta values\n",
    "    for x_i, x in enumerate(X):\n",
    "        for a_i, a in enumerate(a_range):\n",
    "            for b_i, b in enumerate(b_range):\n",
    "                psi = norm.cdf(x,a,b)\n",
    "                # psi = gam + (1 - lam - gam) * norm.cdf(x,a,b)\n",
    "                p_left_look[b_i,a_i,x_i] = psi\n",
    "                p_right_look[b_i,a_i,x_i] = 1-psi\n",
    "\n",
    "    return p_left_look, p_right_look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ebe303f-dda0-4a57-bedc-e6c608b759e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entropy\n",
    "def CalcH(X, p_left_look, p_right_look, Prior):\n",
    "\n",
    "    \"\"\"\n",
    "    This function calculates the entropy (H) of each possible stimulus value to determine which one minimizes,\n",
    "    the entropy for the next trial. This is the stimulus that will provide the most information for both parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    #Simulate through each possible stim value, X\n",
    "    EH, Post_left, Post_right = [], [], []\n",
    "    for i, x in enumerate(X):\n",
    "\n",
    "        #Calculate the probability of getting a response, r, after presenting test x at the next trial (across all possible parameter values)\n",
    "        p_left = np.nansum(np.nansum(np.multiply(p_left_look[:,:,i],Prior)))\n",
    "        p_right = np.nansum(np.nansum(np.multiply(p_right_look[:,:,i],Prior)))\n",
    "\n",
    "        #Calculate the posterior for each response \n",
    "        Post_left = p_left_look[:,:,i]*Prior\n",
    "        Post_left = Post_left / p_left\n",
    "        Post_right = p_right_look[:,:,i]*Prior\n",
    "        Post_right = Post_right / p_right\n",
    "\n",
    "        #Estimate the entropy of the posterior distribution for each response\n",
    "        H_left = -np.nansum(np.nansum(Post_left * np.log2(Post_left)))\n",
    "        H_right = -np.nansum(np.nansum(Post_right * np.log2(Post_right)))\n",
    "        \n",
    "        #Combine the entropy calculations, weighted by their probabilities\n",
    "        Total_H = (H_left*p_left) + (H_right*p_right)\n",
    "        EH = np.append(EH, Total_H)\n",
    "        \n",
    "    best_X = X[np.argmin(EH)]\n",
    "    \n",
    "    return EH, best_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8b02f164-e3dd-4f3a-9b49-13501bebe321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_CCC(sim,est):\n",
    "    \"\"\"\n",
    "    This function calculate the correspondance correlation coefficient\n",
    "    \"\"\"\n",
    "    #Claculate rho\n",
    "    r, _ = stats.pearsonr(sim,est)\n",
    "\n",
    "    #Calculate CCC\n",
    "    CCC = (2*r*np.std(sim)*np.std(est)) / ((np.mean(sim) - np.mean(est))**2 + (np.var(sim) + np.var(est)))\n",
    "\n",
    "    return CCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb01cc7d-bbbb-490a-bf7c-1232338d35e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sim_psi_KT(params, Ntrials, X, a_range, b_range, p_left_look, p_right_look, Prior):\n",
    "    \n",
    "    alpha = params[0]\n",
    "    beta = params[1]\n",
    "    \n",
    "    stims, responses, alpha_EV, beta_EV = [], [], [], []\n",
    "    for i in range(Ntrials):\n",
    "        \n",
    "        #Calculate the best stim position\n",
    "        _, best_X = CalcH(X, p_left_look, p_right_look, Prior)\n",
    "        stims = np.append(stims, best_X)\n",
    "        \n",
    "        #Simualte a response based on the parameters\n",
    "        responses = np.append(responses, norm.cdf(best_X, alpha, beta) > np.random.rand())\n",
    "\n",
    "        #Index the posterior\n",
    "        stim_idx = np.argwhere(stims[i]==X)[0][0]\n",
    "        if responses[i]==1:\n",
    "            Posterior = p_left_look[:,:,stim_idx]*Prior\n",
    "        elif responses[i]==0:\n",
    "            Posterior = p_right_look[:,:,stim_idx]*Prior\n",
    "        Posterior = Posterior/np.nansum(np.nansum(Posterior))\n",
    "        \n",
    "        #Marginalize the posterior\n",
    "        alpha_post = np.nansum(Posterior,axis=0)\n",
    "        beta_post = np.nansum(Posterior,axis=1)\n",
    "\n",
    "        #Calculate the expected value of each\n",
    "        alpha_EV = np.append(alpha_EV, np.nansum(a_range*alpha_post))\n",
    "        beta_EV = np.append(beta_EV, np.nansum(b_range*beta_post))\n",
    "\n",
    "        #The posterior becomes the prior for the next trial\n",
    "        Prior = Posterior        \n",
    "        \n",
    "    return stims, responses, alpha_EV, beta_EV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f1229e-7741-4762-ab2d-12203668646b",
   "metadata": {},
   "source": [
    "# Set variables for each method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3930bba-17ad-4e5e-9e5a-d49f17fd97e2",
   "metadata": {},
   "source": [
    "## Set the lookup table and the prior (for psi method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad70d63-ff56-487c-9a08-937e8a398e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(-100,110,10)\n",
    "a_range = np.linspace(-100,100,201) \n",
    "b_range = np.linspace(0.001,100,201)\n",
    "p_left_look, p_right_look = Psi_lookT(X, a_range, b_range)\n",
    "\n",
    "#Set the priors\n",
    "p_alpha = norm.pdf(a_range,0, 20)\n",
    "p_beta = expon.pdf(b_range,0,20)\n",
    "p_alpha = np.reshape(p_alpha,(1,len(p_alpha)))\n",
    "p_beta = np.reshape(p_beta,(1,len(p_beta)))\n",
    "Prior = p_beta.T @ p_alpha\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58c37b1-a26c-434e-8239-17723b644a06",
   "metadata": {},
   "source": [
    "## Set stimuli range for the method of constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "434ff619-a237-44db-8c54-b7b7fade3b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-100.,  -46.,  -22.,  -10.,    0.,   10.,   22.,   46.,  100.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logspace the array so it can cover a wider space\n",
    "X_constants = np.round(np.logspace(1,2,4))\n",
    "X_constants = np.concatenate((-np.flip(X_constants), np.zeros(1), X_constants))\n",
    "X_constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcadecb1-644e-47af-b9b3-97b86aa1a4c0",
   "metadata": {},
   "source": [
    "# Simulate an individual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
